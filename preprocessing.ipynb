{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QuTEtW723qUd"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import ImageOps, Image\n",
        "from google.colab.patches import cv2_imshow\n",
        "from matplotlib.colors import ListedColormap\n",
        "from tqdm import tqdm\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s8b6VpfvmmXv",
        "outputId": "c76e6919-e748-41b4-b49f-895b1d50013b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN_JSON_PATH = '/content/drive/MyDrive/Colab Notebooks/Data/label/train/'\n",
        "VALID_JSON_PATH = '/content/drive/MyDrive/Colab Notebooks/Data/label/val/'\n",
        "\n",
        "TRAIN_IMG_PATH = '/content/drive/MyDrive/Colab Notebooks/Data/img/train/'\n",
        "VALID_IMG_PATH = '/content/drive/MyDrive/Colab Notebooks/Data/img/val/'\n",
        "\n",
        "TRAIN_SEGMENT_PATH = '/content/drive/MyDrive/Colab Notebooks/myData/segmentation/train/'\n",
        "VALID_SEGMENT_PATH = '/content/drive/MyDrive/Colab Notebooks/myData/segmentation/val/'\n",
        "\n",
        "CSV_PATH = '/content/drive/MyDrive/Colab Notebooks/myData/'\n",
        "\n",
        "PREPROC_TRAIN_IMG_PATH = '/content/drive/MyDrive/Colab Notebooks/myData/preprocessed/train/'"
      ],
      "metadata": {
        "id": "vm6VWTDCm5EQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(CSV_PATH + 'train_ver3.csv')"
      ],
      "metadata": {
        "id": "03B7-ElSav26"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "happy_npz = np.load(TRAIN_SEGMENT_PATH + f'train_happy.npz')\n",
        "anger_npz = np.load(TRAIN_SEGMENT_PATH + f'train_anger.npz')\n",
        "sadness_npz = np.load(TRAIN_SEGMENT_PATH + f'train_sadness.npz')\n",
        "panic_npz = np.load(TRAIN_SEGMENT_PATH + f'train_panic.npz')"
      ],
      "metadata": {
        "id": "CeIqI4XvJeCk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train 함수\n",
        "def segmentation_images(imgfile, emotion):\n",
        "    file_name = imgfile.split('/')[-1]\n",
        "    if emotion == 'happy':\n",
        "      npz = happy_npz\n",
        "    elif emotion == 'anger':\n",
        "      npz = anger_npz\n",
        "    elif emotion == 'sadness':\n",
        "      npz = sadness_npz\n",
        "    elif emotion == 'panic':\n",
        "      npz = panic_npz\n",
        "\n",
        "    segment_mask = npz[file_name]\n",
        "\n",
        "    # img = Image.open(imgfile).convert('RGB')\n",
        "    # img = ImageOps.exif_transpose(img)\n",
        "\n",
        "    img = cv2.imread(imgfile)\n",
        "    # img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "    # np_img = np.array(img)\n",
        "    img[segment_mask != 3] = 0\n",
        "\n",
        "    # seg_img = Image.fromarray(np_img)\n",
        "\n",
        "    return img"
      ],
      "metadata": {
        "id": "JSXTii2b4bLF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fault_list = []"
      ],
      "metadata": {
        "id": "o3tXtuyZf0NP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def crop_images(filepath, coordinates, emotion): # coordinates = (df['annot_A.boxes.minX'][i], df['annot_A.boxes.minY'][i], df['annot_A.boxes.maxX'][i], df['annot_A.boxes.maxY'][i])\n",
        "    # img = Image.open(filepath).convert('RGB')\n",
        "    # img = ImageOps.exif_transpose(img)\n",
        "    img = cv2.imread(filepath)\n",
        "    #img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
        "    #croped_img = seg_img.crop(coordinates)\n",
        "    for c in coordinates:\n",
        "      if c < 0:\n",
        "        fault_list.append((filepath.split('/')[-1], emotion))\n",
        "        print(filepath.split('/')[-1])\n",
        "        del img\n",
        "        return None\n",
        "    croped_img = img[int(coordinates[0]):int(coordinates[1]), int(coordinates[2]):int(coordinates[3])]\n",
        "\n",
        "    del img\n",
        "\n",
        "    return croped_img"
      ],
      "metadata": {
        "id": "yTkpVQ0G4cS6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filenames = list(df['filename'])\n",
        "emotions = list(df['faceExp_uploader'])"
      ],
      "metadata": {
        "id": "7dJw4zIvUyai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # All files segmentation\n",
        "# for i in tqdm(range(len(filenames))):\n",
        "#     save_path = PREPROC_TRAIN_IMG_PATH\n",
        "#     if emotions[i] == 0:\n",
        "#         emotion = 'happy'\n",
        "#     elif emotions[i] == 1:\n",
        "#         emotion = 'anger'\n",
        "#     elif emotions[i] == 2:\n",
        "#         emotion = 'sadness'\n",
        "#     elif emotions[i] == 3:\n",
        "#         emotion = 'panic'\n",
        "#     else:\n",
        "#         print('NOT SUPPORTED EMOTION')\n",
        "#         continue\n",
        "\n",
        "#     seg_img = segmentation_images(TRAIN_IMG_PATH + emotion + '/' + filenames[i], emotion)\n",
        "\n",
        "#     if not os.path.exists(save_path):\n",
        "#         os.makedirs(save_path)\n",
        "#     save_path += 'segmentation/'\n",
        "#     os.makedirs(save_path, exist_ok=True)\n",
        "#     save_path += emotion + '/'\n",
        "#     os.makedirs(save_path, exist_ok=True)\n",
        "#     cv2.imwrite(save_path + filenames[i], seg_img)"
      ],
      "metadata": {
        "id": "HlmB6eqegLDO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# All files crop\n",
        "for i in tqdm(range(len(filenames))):\n",
        "    save_path = PREPROC_TRAIN_IMG_PATH\n",
        "    emotion = \"\"\n",
        "    if emotions[i] == 0:\n",
        "        emotion += 'happy'\n",
        "    elif emotions[i] == 1:\n",
        "        emotion += 'anger'\n",
        "    elif emotions[i] == 2:\n",
        "        emotion += 'sadness'\n",
        "    elif emotions[i] == 3:\n",
        "        emotion += 'panic'\n",
        "    else:\n",
        "        print('NOT SUPPORTED EMOTION')\n",
        "        continue\n",
        "\n",
        "    coordinate = (df['minY'][i], df['maxY'][i], df['minX'][i], df['maxX'][i])\n",
        "    croped_img = crop_images(TRAIN_IMG_PATH + emotion + '/' + filenames[i], coordinate, emotion)\n",
        "    if croped_img is None:\n",
        "      continue\n",
        "    if not os.path.exists(save_path):\n",
        "        os.makedirs(save_path)\n",
        "    save_path += 'crop/'\n",
        "    if not os.path.exists(save_path):\n",
        "      os.makedirs(save_path, exist_ok=True)\n",
        "    save_path += emotion + '/'\n",
        "    if not os.path.exists(save_path):\n",
        "      os.makedirs(save_path, exist_ok=True)\n",
        "    cv2.imwrite(save_path + filenames[i], croped_img)\n",
        "    del croped_img\n",
        "    del save_path\n",
        "    del emotion"
      ],
      "metadata": {
        "id": "b9UXd80ogNYd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ab3b4ec-eaf1-451c-ae0a-26f280b31257"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5992/5992 [2:36:16<00:00,  1.56s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('크롭 실패 목록')\n",
        "print(fault_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jtqRf3jqiF69",
        "outputId": "e2145d02-b2b7-47f5-87d4-b9017559c743"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "크롭 실패 목록\n",
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(fault_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WvwEjb4IKUbJ",
        "outputId": "1cfc2aef-9cbe-47c9-9e1b-ebaae4bf68ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print(PREPROC_TRAIN_IMG_PATH + emotion + '/' + filenames[0])"
      ],
      "metadata": {
        "id": "6hEp6H5yKm9e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# All files segmentation & crop\n",
        "for i in tqdm(range(len(filenames))):\n",
        "    save_path = PREPROC_TRAIN_IMG_PATH\n",
        "    if emotions[i] == 0:\n",
        "        emotion = 'happy'\n",
        "    elif emotions[i] == 1:\n",
        "        emotion = 'anger'\n",
        "    elif emotions[i] == 2:\n",
        "        emotion = 'sadness'\n",
        "    elif emotions[i] == 3:\n",
        "        emotion = 'panic'\n",
        "    else:\n",
        "        print('NOT SUPPORTED EMOTION')\n",
        "        continue\n",
        "\n",
        "    coordinate = (df['minY'][i], df['maxY'][i], df['minX'][i], df['maxX'][i])\n",
        "    croped_img = crop_images(PREPROC_TRAIN_IMG_PATH + 'segmentation/' + emotion + '/' + filenames[i], coordinate, emotion)\n",
        "    if croped_img is None:\n",
        "        continue\n",
        "    mean_val1 = np.mean(croped_img, axis=0)\n",
        "    mean_val2 = np.mean(mean_val1)\n",
        "    if mean_val2 < 10:\n",
        "        print(\"black image: \", filenames[i], f'index: {i}')\n",
        "        continue\n",
        "    if not os.path.exists(save_path):\n",
        "        os.makedirs(save_path)\n",
        "    save_path += 'segmentation_and_crop/'\n",
        "    if not os.path.exists(save_path):\n",
        "      os.makedirs(save_path, exist_ok=True)\n",
        "    save_path += emotion + '/'\n",
        "    if not os.path.exists(save_path):\n",
        "      os.makedirs(save_path, exist_ok=True)\n",
        "    cv2.imwrite(save_path + filenames[i], croped_img)"
      ],
      "metadata": {
        "id": "Hh_b5iC4Fdn6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc3aecc6-f21a-4e1d-94d2-139ac53ac07d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5992/5992 [1:53:30<00:00,  1.14s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_val = pd.read_csv(CSV_PATH + 'valid_ver3.csv')"
      ],
      "metadata": {
        "id": "2Y28fWqfJUUi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PREPROC_VALID_IMG_PATH = '/content/drive/MyDrive/Colab Notebooks/myData/preprocessed/val/'"
      ],
      "metadata": {
        "id": "7LAHOnShKuHE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del happy_npz\n",
        "del anger_npz\n",
        "del sadness_npz\n",
        "del panic_npz"
      ],
      "metadata": {
        "id": "25vmq2ctKNPB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "happy_npz = np.load(VALID_SEGMENT_PATH + f'val_happy.npz')\n",
        "anger_npz = np.load(VALID_SEGMENT_PATH + f'val_anger.npz')\n",
        "sadness_npz = np.load(VALID_SEGMENT_PATH + f'val_sadness.npz')\n",
        "panic_npz = np.load(VALID_SEGMENT_PATH + f'val_panic.npz')"
      ],
      "metadata": {
        "id": "1kioDpGbKLjF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fault_list.clear()\n",
        "filenames.clear()\n",
        "emotions.clear()"
      ],
      "metadata": {
        "id": "xl--DRqfJ4lf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fault_list = []\n",
        "filenames = list(df_val['filename'])\n",
        "emotions = list(df_val['faceExp_uploader'])"
      ],
      "metadata": {
        "id": "TVjqVceTJ_CM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# All files segmentation\n",
        "for i in tqdm(range(len(filenames))):\n",
        "    save_path = PREPROC_VALID_IMG_PATH\n",
        "    if emotions[i] == 0:\n",
        "        emotion = 'happy'\n",
        "    elif emotions[i] == 1:\n",
        "        emotion = 'anger'\n",
        "    elif emotions[i] == 2:\n",
        "        emotion = 'sadness'\n",
        "    elif emotions[i] == 3:\n",
        "        emotion = 'panic'\n",
        "    else:\n",
        "        print('NOT SUPPORTED EMOTION')\n",
        "        continue\n",
        "\n",
        "    seg_img = segmentation_images(VALID_IMG_PATH + emotion + '/' + filenames[i], emotion)\n",
        "\n",
        "    if not os.path.exists(save_path):\n",
        "        os.makedirs(save_path)\n",
        "    save_path += 'segmentation/'\n",
        "    os.makedirs(save_path, exist_ok=True)\n",
        "    save_path += emotion + '/'\n",
        "    os.makedirs(save_path, exist_ok=True)\n",
        "    cv2.imwrite(save_path + filenames[i], seg_img)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DgsyEGexJngK",
        "outputId": "a9f37c8d-0fff-412f-fb9e-8a107accbaa8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1200/1200 [40:42<00:00,  2.04s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# All files crop\n",
        "for i in tqdm(range(len(filenames))):\n",
        "    save_path = PREPROC_VALID_IMG_PATH\n",
        "    emotion = \"\"\n",
        "    if emotions[i] == 0:\n",
        "        emotion += 'happy'\n",
        "    elif emotions[i] == 1:\n",
        "        emotion += 'anger'\n",
        "    elif emotions[i] == 2:\n",
        "        emotion += 'sadness'\n",
        "    elif emotions[i] == 3:\n",
        "        emotion += 'panic'\n",
        "    else:\n",
        "        print('NOT SUPPORTED EMOTION')\n",
        "        continue\n",
        "\n",
        "    coordinate = (df_val['minY'][i], df_val['maxY'][i], df_val['minX'][i], df_val['maxX'][i])\n",
        "    croped_img = crop_images(VALID_IMG_PATH + emotion + '/' + filenames[i], coordinate, emotion)\n",
        "    if croped_img is None:\n",
        "      continue\n",
        "    if not os.path.exists(save_path):\n",
        "        os.makedirs(save_path)\n",
        "    save_path += 'crop/'\n",
        "    if not os.path.exists(save_path):\n",
        "      os.makedirs(save_path, exist_ok=True)\n",
        "    save_path += emotion + '/'\n",
        "    if not os.path.exists(save_path):\n",
        "      os.makedirs(save_path, exist_ok=True)\n",
        "    cv2.imwrite(save_path + filenames[i], croped_img)\n",
        "    del croped_img\n",
        "    del save_path\n",
        "    del emotion"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rR_6yk_SKZSv",
        "outputId": "fdd39d4a-bdbf-4deb-9611-279f22b64656"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1200/1200 [03:14<00:00,  6.18it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('크롭 실패 목록')\n",
        "print(fault_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZ33lErLLpiV",
        "outputId": "11f01b1d-f2ce-49e1-d5d7-e6415e70b666"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "크롭 실패 목록\n",
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(fault_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pi2zng8cL8I0",
        "outputId": "887e2067-a948-421f-a11a-c763c1f0244e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# All files segmentation & crop\n",
        "for i in tqdm(range(len(filenames))):\n",
        "    save_path = PREPROC_VALID_IMG_PATH\n",
        "    if emotions[i] == 0:\n",
        "        emotion = 'happy'\n",
        "    elif emotions[i] == 1:\n",
        "        emotion = 'anger'\n",
        "    elif emotions[i] == 2:\n",
        "        emotion = 'sadness'\n",
        "    elif emotions[i] == 3:\n",
        "        emotion = 'panic'\n",
        "    else:\n",
        "        print('NOT SUPPORTED EMOTION')\n",
        "        continue\n",
        "\n",
        "    coordinate = (df_val['minY'][i], df_val['maxY'][i], df_val['minX'][i], df_val['maxX'][i])\n",
        "    croped_img = crop_images(PREPROC_VALID_IMG_PATH + 'segmentation/' + emotion + '/' + filenames[i], coordinate, emotion)\n",
        "    if croped_img is None:\n",
        "        continue\n",
        "    mean_val1 = np.mean(croped_img, axis=0)\n",
        "    mean_val2 = np.mean(mean_val1)\n",
        "    if mean_val2 < 10:\n",
        "        print(\"black image: \", filenames[i], f'index: {i}')\n",
        "        continue\n",
        "    if not os.path.exists(save_path):\n",
        "        os.makedirs(save_path)\n",
        "    save_path += 'segmentation_and_crop/'\n",
        "    if not os.path.exists(save_path):\n",
        "      os.makedirs(save_path, exist_ok=True)\n",
        "    save_path += emotion + '/'\n",
        "    if not os.path.exists(save_path):\n",
        "      os.makedirs(save_path, exist_ok=True)\n",
        "    cv2.imwrite(save_path + filenames[i], croped_img)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TGCLhiBFKZeK",
        "outputId": "fd59de91-e686-43fd-a8a4-d66fdf6de1cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 30%|███       | 362/1200 [00:44<01:19, 10.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "black image:  rb04c532132d836a981bf48f70b3588730632285f2c97b347e1cdb4fa1133mcty.jpg index: 359\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1200/1200 [02:31<00:00,  7.93it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_val[df_val['filename']=='rb04c532132d836a981bf48f70b3588730632285f2c97b347e1cdb4fa1133mcty.jpg']"
      ],
      "metadata": {
        "id": "MZ3LUzc9MZ-x",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "outputId": "9d6c5022-6787-4cd9-8dcb-4c726162e81f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Unnamed: 0                                           filename  gender  \\\n",
              "359         359  rb04c532132d836a981bf48f70b3588730632285f2c97b...       0   \n",
              "\n",
              "     age  isProf  faceExp_uploader  bg_uploader annot_A.faceExp annot_A.bg  \\\n",
              "359   50       0                 2            6              슬픔  숙박 및 거주공간   \n",
              "\n",
              "    annot_B.faceExp  ... annot_C.faceExp annot_C.bg  lenX  lenY         minX  \\\n",
              "359              슬픔  ...              슬픔  숙박 및 거주공간  2640  1980  1689.859096   \n",
              "\n",
              "            maxX        minY         maxY       face.X      face.Y  \n",
              "359  2543.880496  243.076451  1342.284391  2116.869796  792.680421  \n",
              "\n",
              "[1 rows x 21 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bc60ea7f-9b2f-4144-bf95-666fd2907513\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>filename</th>\n",
              "      <th>gender</th>\n",
              "      <th>age</th>\n",
              "      <th>isProf</th>\n",
              "      <th>faceExp_uploader</th>\n",
              "      <th>bg_uploader</th>\n",
              "      <th>annot_A.faceExp</th>\n",
              "      <th>annot_A.bg</th>\n",
              "      <th>annot_B.faceExp</th>\n",
              "      <th>...</th>\n",
              "      <th>annot_C.faceExp</th>\n",
              "      <th>annot_C.bg</th>\n",
              "      <th>lenX</th>\n",
              "      <th>lenY</th>\n",
              "      <th>minX</th>\n",
              "      <th>maxX</th>\n",
              "      <th>minY</th>\n",
              "      <th>maxY</th>\n",
              "      <th>face.X</th>\n",
              "      <th>face.Y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>359</th>\n",
              "      <td>359</td>\n",
              "      <td>rb04c532132d836a981bf48f70b3588730632285f2c97b...</td>\n",
              "      <td>0</td>\n",
              "      <td>50</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>슬픔</td>\n",
              "      <td>숙박 및 거주공간</td>\n",
              "      <td>슬픔</td>\n",
              "      <td>...</td>\n",
              "      <td>슬픔</td>\n",
              "      <td>숙박 및 거주공간</td>\n",
              "      <td>2640</td>\n",
              "      <td>1980</td>\n",
              "      <td>1689.859096</td>\n",
              "      <td>2543.880496</td>\n",
              "      <td>243.076451</td>\n",
              "      <td>1342.284391</td>\n",
              "      <td>2116.869796</td>\n",
              "      <td>792.680421</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1 rows × 21 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bc60ea7f-9b2f-4144-bf95-666fd2907513')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bc60ea7f-9b2f-4144-bf95-666fd2907513 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bc60ea7f-9b2f-4144-bf95-666fd2907513');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pbVJphyG2qrs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}